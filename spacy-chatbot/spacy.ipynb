{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_words = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)['intents']\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "tag_to_response = {}\n",
    "classes = []\n",
    "for intent in intents:\n",
    "    tag=intent['tag']\n",
    "    if tag not in classes:\n",
    "        classes.append(tag)\n",
    "    tag_to_response[tag] = intent['responses']\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokens = tokenizer(pattern)\n",
    "        # if len(tokens) < max_words:\n",
    "        #     tokens += (max_words - len(tokens))*[\"\"]\n",
    "        # else:\n",
    "        #     tokens = tokens[:max_words]\n",
    "        X.append(pattern)\n",
    "        y.append(classes.index(tag))\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.3619e+00,  6.4227e-01,  3.6572e+00,  1.2839e-05, -4.9597e+00,\n",
       "       -3.7551e+00, -7.2010e-01, -3.8699e+00, -6.4149e+00, -2.1970e+00,\n",
       "       -1.4052e+00,  2.0386e+00, -6.1365e+00,  1.4983e+00,  7.4897e-02,\n",
       "       -2.8394e+00, -6.8990e-01,  1.0237e+00, -2.3867e+00, -2.4802e+00,\n",
       "        4.8034e+00,  4.0907e-01, -5.9518e-01, -9.6808e+00,  1.0078e+00,\n",
       "       -2.6209e+00,  1.6237e+00, -1.2758e+00, -3.3642e+00,  2.5376e+00,\n",
       "       -8.2612e+00, -2.0550e+00, -3.5853e+00,  2.5571e+00,  3.4179e+00,\n",
       "        4.8266e+00, -4.7334e+00,  1.4521e+00,  1.9508e+00, -3.5734e+00,\n",
       "        7.1136e-01, -4.0711e+00, -2.3756e+00,  2.9331e+00, -1.0385e+00,\n",
       "        8.0737e-01, -1.0357e+01,  1.0074e+00, -2.3647e+00,  4.6682e+00,\n",
       "       -5.6539e+00, -8.9656e+00, -4.4444e-02,  4.0555e-01,  5.9755e+00,\n",
       "       -2.6969e+00,  3.1529e+00,  1.7365e+00,  8.0275e-01,  2.4104e+00,\n",
       "        2.2166e+00,  4.9589e+00, -2.3379e+00, -5.4958e+00,  1.0721e-01,\n",
       "       -1.8430e+00, -3.3400e+00,  5.7293e+00, -2.7006e+00,  1.6596e+00,\n",
       "       -1.9317e+00,  1.4342e+00,  5.9920e+00, -1.2480e+01,  5.6180e-01,\n",
       "       -5.3726e+00,  1.9404e+00, -2.2387e+00,  2.3726e+00, -7.1080e+00,\n",
       "        1.8596e+00, -6.7751e+00,  1.9078e+00, -4.0242e+00, -2.3757e+00,\n",
       "        2.4642e+00,  1.1714e+01,  4.9008e+00,  2.1947e+00, -3.7230e+00,\n",
       "        2.3048e+00, -6.8884e-01,  2.5573e+00, -3.2420e+00, -6.2947e+00,\n",
       "        2.8473e+00,  3.0592e-01, -6.8223e+00,  2.3680e+00,  3.2889e+00,\n",
       "       -3.6433e+00,  2.8609e+00,  1.9663e+00, -4.4155e+00,  2.4699e+00,\n",
       "        4.6545e+00,  5.4649e+00,  3.1985e-01, -6.7960e+00,  3.0742e+00,\n",
       "       -1.1667e+01, -1.9584e+00,  1.1205e+01,  2.7294e+00,  3.4613e-01,\n",
       "        3.3248e+00,  7.5238e+00, -3.8610e+00,  5.5736e+00, -8.3865e+00,\n",
       "       -5.2493e+00, -1.6204e+00,  4.8186e+00,  6.2106e+00,  2.0364e+00,\n",
       "        2.0662e+00, -5.0398e+00, -3.4303e-01, -2.4480e+00,  3.2120e+00,\n",
       "        2.2141e-01,  1.7477e+00,  1.2831e+00, -1.1928e+00,  4.1080e+00,\n",
       "       -1.4330e+00, -1.9931e+00, -5.0847e+00,  1.5044e+00,  4.0365e+00,\n",
       "       -3.3825e+00, -5.3423e-01,  5.3968e+00, -2.7001e+00,  6.0300e+00,\n",
       "       -2.7277e+00,  1.8549e+00,  9.1918e-01,  5.8658e+00,  6.6773e-01,\n",
       "       -1.2253e+00, -7.4921e-01, -7.1712e+00,  5.3806e-01, -4.9737e+00,\n",
       "        6.3197e-01,  2.8652e+00, -9.1008e-01, -2.7025e+00,  1.3942e+00,\n",
       "       -2.2845e+00, -5.8176e+00, -1.7961e+00, -3.0163e-01,  5.8690e+00,\n",
       "        8.8021e+00,  2.3984e+00, -3.5991e+00,  1.8370e+00, -3.3989e+00,\n",
       "        1.4575e+00, -2.0206e+00,  3.5637e+00,  2.4592e+00,  7.0106e+00,\n",
       "       -2.0890e+00, -5.2210e+00,  3.7000e+00, -3.8991e+00,  6.4252e+00,\n",
       "       -6.2020e+00,  9.7215e+00, -3.9394e+00, -2.3729e+00,  1.6780e+00,\n",
       "        1.0170e+01,  1.0230e+01, -2.4489e+00, -2.5244e+00, -3.8501e+00,\n",
       "       -6.2446e+00,  6.3187e+00, -5.0657e+00,  4.6256e+00,  8.1218e+00,\n",
       "        4.6931e+00, -2.9192e+00, -3.6342e-01,  3.7639e+00,  2.2232e+00,\n",
       "       -5.7315e+00, -1.7354e+00,  1.8586e+00,  7.9394e+00, -6.4458e+00,\n",
       "       -2.3297e-03, -4.8855e-01, -1.5099e+00,  4.7730e+00, -7.3111e+00,\n",
       "        6.9499e+00, -1.1539e+00,  4.9626e+00, -4.4408e+00,  4.5780e+00,\n",
       "       -8.2648e+00,  8.3764e+00, -3.8305e+00, -1.2854e+00,  1.0031e+00,\n",
       "       -5.2115e+00, -1.6393e+00,  4.3350e+00, -8.3479e+00,  3.8565e+00,\n",
       "        6.0271e+00, -2.6119e+00, -4.7048e+00,  6.6836e-01, -4.2052e+00,\n",
       "       -5.4271e+00, -2.1105e-01, -1.0156e+00, -2.3815e+00,  4.4306e-01,\n",
       "       -6.7641e+00,  2.4689e+00, -1.1465e-01,  7.1325e+00,  3.7544e+00,\n",
       "       -1.5761e+00,  3.4745e+00,  8.4051e-01,  1.5642e+00,  6.2416e+00,\n",
       "       -7.5960e+00,  6.3990e+00,  4.0353e-01,  1.9599e+00, -1.4657e+00,\n",
       "       -4.6275e+00,  2.7541e+00, -4.2659e+00,  2.9987e-01,  1.6867e+00,\n",
       "       -3.6663e+00,  4.1305e+00,  7.0274e-01, -7.3210e+00,  4.9130e+00,\n",
       "       -2.8375e+00, -5.9283e+00,  7.7855e-01, -6.1090e+00, -1.3074e+00,\n",
       "        8.6670e-01, -7.4418e+00, -1.4302e+00,  6.1679e+00, -2.9743e-01,\n",
       "       -4.7900e+00,  3.0289e+00,  3.8136e-01,  2.9662e+00, -3.0579e+00,\n",
       "       -4.8936e-01,  4.9656e+00, -1.2374e-02, -2.1613e-02,  2.0405e+00,\n",
       "       -5.2276e+00,  5.4328e+00, -1.6502e+00, -3.1327e+00,  1.3002e+00,\n",
       "        6.3884e+00, -4.7490e-01,  4.2537e+00,  4.4334e+00,  3.6826e+00,\n",
       "       -2.7493e+00,  8.5395e+00,  2.0633e+00, -1.2086e+00, -3.9757e+00,\n",
       "       -2.3832e+00, -3.7726e-01, -7.9965e-01, -3.0122e+00, -1.5884e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "# English pipelines include a rule-based lemmatizer\n",
    "nlp = spacy.load(\"en_core_web_lg\", exclude=[\"ner\",\"parser\"])\n",
    "docs = nlp.pipe(X)\n",
    "\n",
    "included_pos_tags = ['ADJ','ADV','INTJ','NOUN', 'PROPN', 'VERB']\n",
    "excluded_pos_tags = ['PUNCT', 'SYM', 'X', 'AUX']\n",
    "processed_X = []\n",
    "for doc in docs:\n",
    "    token_vectors = [nlp(token.lemma_)[0].vector for token in doc if token.pos_ not in excluded_pos_tags]\n",
    "    # if len(token_vectors) < max_words:\n",
    "    #     token_vectors += [nlp(\" \")[0].vector]*max_words\n",
    "    # else:\n",
    "    #     token_vectors = token_vectors[:max_words]\n",
    "    \n",
    "    processed_X.append(np.average(token_vectors, axis=0))\n",
    "\n",
    "processed_X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.n_samples = len(X)\n",
    "        self.x_data = X\n",
    "        self.y_data = y\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = ChatDataset(processed_X,y)\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.1067\n",
      "Epoch [20/100], Loss: 0.0045\n",
      "Epoch [30/100], Loss: 0.0021\n",
      "Epoch [40/100], Loss: 0.0014\n",
      "Epoch [50/100], Loss: 0.0011\n",
      "Epoch [60/100], Loss: 0.0011\n",
      "Epoch [70/100], Loss: 0.0007\n",
      "Epoch [80/100], Loss: 0.0006\n",
      "Epoch [90/100], Loss: 0.0005\n",
      "Epoch [100/100], Loss: 0.0004\n",
      "final loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "embed_len = 300\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from model import EmbeddingClassifier\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = EmbeddingClassifier(max_words=1, embed_len=embed_len, num_classes=len(classes)).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(words)\n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"classes\": classes,\n",
    "\"lr\": learning_rate,\n",
    "\"max_words\": 1,\n",
    "\"embed_length\": embed_len,\n",
    "'tag_to_response': tag_to_response\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a Full Length Feature Film Script  In this course, you will write a complete, feature-length screenplay for film or television, be it a serious drama or romantic comedy or anything in between. You�ll learn to break down the creative process into components, and you�ll discover a structured process that allows you to produce a polished and pitch-ready script by the end of the course. Completing this project will increase your confidence in your ideas and abilities, and you�ll feel prepared to pitch your first script and get started on your next. This is a course designed to tap into your creativity and is based in \"Active Learning\". Most of the actual learning takes place within your own activities - that is, writing! You will learn by doing.  Here is a link to a TRAILER for the course. To view the trailer, please copy and paste the link into your browser. https://vimeo.com/382067900/b78b800dc0  Learner review: \"Love the approach Professor Wheeler takes towards this course. It\\'s to the point, easy to follow, and very informative! Would definitely recommend it to anyone who is interested in taking a Screenplay Writing course!  The course curriculum is simple: We will adopt a professional writers room process in which you�ll write, post your work for peer review, share feedback with your peers and revise your work with the feedback you receive from your peers. That\\'s how we do it in the real world. You will feel as if you were in a professional writers room yet no prior experience as a writer is required. I\\'m a proponent of Experiential Learning (Active Learning). My lectures are short (sometimes just two minutes long) and to the point, designed in a step-by-step process essential to your success as a script writer. I will guide you but I won�t \"show\" you how to write. I firmly believe that the only way to become a writer is to write, write, write.  Learner Review: \"I would like to thank this course instructor. It\\'s an amazing course\"  What you�ll need to get started: As mentioned above, no prior script writing experience is required. To begin with, any basic word processor will do. During week two, you can choose to download some free scriptwriting software such as Celtx or Trelby or you may choose to purchase Final Draft, the industry standard, or you can continue to use your word processor and do your own script formatting.   Learner Review: \"Now I am a writer!\"  If you have any concerns regarding the protection of your original work, Coursera\\'s privacy policy protects the learner\\'s IP and you are indeed the sole owners of your work.'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Coursera.csv')\n",
    "df['Course Description'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Name</th>\n",
       "      <th>University</th>\n",
       "      <th>Difficulty Level</th>\n",
       "      <th>Course Rating</th>\n",
       "      <th>Course URL</th>\n",
       "      <th>Course Description</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>Process Mining: Data science in Action</td>\n",
       "      <td>Eindhoven University of Technology</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>4.8</td>\n",
       "      <td>https://www.coursera.org/learn/process-mining</td>\n",
       "      <td>Process mining is the missing link between mod...</td>\n",
       "      <td>process modeling  business process  Process Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Data-driven Astronomy</td>\n",
       "      <td>The University of Sydney</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>4.8</td>\n",
       "      <td>https://www.coursera.org/learn/data-driven-ast...</td>\n",
       "      <td>Science is undergoing a data explosion, and as...</td>\n",
       "      <td>Computer Programming  Python Programming  SQL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>A Crash Course in Data Science</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>Conversant</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://www.coursera.org/learn/data-science-co...</td>\n",
       "      <td>By now you have definitely heard about data sc...</td>\n",
       "      <td>analysis  Machine Learning  software  Human Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Introduction to Data Analytics</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>4.7</td>\n",
       "      <td>https://www.coursera.org/learn/introduction-to...</td>\n",
       "      <td>This course presents a gentle introduction int...</td>\n",
       "      <td>analytics  Data Analysis  physics  Exploratory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Building a Data Science Team</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>4.5</td>\n",
       "      <td>https://www.coursera.org/learn/build-data-scie...</td>\n",
       "      <td>Data science is a team sport. As a data scienc...</td>\n",
       "      <td>Data Analysis  team management  Team Building ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>Using clinical health data for better healthcare</td>\n",
       "      <td>The University of Sydney</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>4.6</td>\n",
       "      <td>https://www.coursera.org/learn/healthcare-data</td>\n",
       "      <td>Digital health is rapidly being realised as th...</td>\n",
       "      <td>data integrity  health human resources  Health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>Big Data Modeling and Management Systems</td>\n",
       "      <td>University of California San Diego</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://www.coursera.org/learn/big-data-manage...</td>\n",
       "      <td>Once you�ve identified a big data issue to ana...</td>\n",
       "      <td>Databases  analytics  graphs  Data Structures ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>Fundamentals of Scalable Data Science</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://www.coursera.org/learn/ds</td>\n",
       "      <td>Apache Spark is the de-facto standard for larg...</td>\n",
       "      <td>General Statistics  Dimensionality Reduction  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>SQL for Data Science</td>\n",
       "      <td>University of California, Davis</td>\n",
       "      <td>Conversant</td>\n",
       "      <td>4.5</td>\n",
       "      <td>https://www.coursera.org/learn/sql-for-data-sc...</td>\n",
       "      <td>As data collection has increased exponentially...</td>\n",
       "      <td>modeling  Databases  data retrieval  analysis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>Excel Basics for Data Analysis</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>4.7</td>\n",
       "      <td>https://www.coursera.org/learn/excel-basics-da...</td>\n",
       "      <td>This course is designed to provide you with ba...</td>\n",
       "      <td>euler's totient function  Pivot Table  workshe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Course Name  \\\n",
       "2701            Process Mining: Data science in Action   \n",
       "205                              Data-driven Astronomy   \n",
       "2355                    A Crash Course in Data Science   \n",
       "1204                    Introduction to Data Analytics   \n",
       "329                       Building a Data Science Team   \n",
       "2798  Using clinical health data for better healthcare   \n",
       "2710          Big Data Modeling and Management Systems   \n",
       "2804             Fundamentals of Scalable Data Science   \n",
       "1580                              SQL for Data Science   \n",
       "1148                    Excel Basics for Data Analysis   \n",
       "\n",
       "                              University Difficulty Level Course Rating  \\\n",
       "2701  Eindhoven University of Technology         Beginner           4.8   \n",
       "205             The University of Sydney         Advanced           4.8   \n",
       "2355            Johns Hopkins University       Conversant           4.4   \n",
       "1204                                 IBM         Advanced           4.7   \n",
       "329             Johns Hopkins University     Intermediate           4.5   \n",
       "2798            The University of Sydney     Intermediate           4.6   \n",
       "2710  University of California San Diego     Intermediate           4.4   \n",
       "2804                                 IBM         Advanced           4.1   \n",
       "1580     University of California, Davis       Conversant           4.5   \n",
       "1148                                 IBM         Advanced           4.7   \n",
       "\n",
       "                                             Course URL  \\\n",
       "2701      https://www.coursera.org/learn/process-mining   \n",
       "205   https://www.coursera.org/learn/data-driven-ast...   \n",
       "2355  https://www.coursera.org/learn/data-science-co...   \n",
       "1204  https://www.coursera.org/learn/introduction-to...   \n",
       "329   https://www.coursera.org/learn/build-data-scie...   \n",
       "2798     https://www.coursera.org/learn/healthcare-data   \n",
       "2710  https://www.coursera.org/learn/big-data-manage...   \n",
       "2804                  https://www.coursera.org/learn/ds   \n",
       "1580  https://www.coursera.org/learn/sql-for-data-sc...   \n",
       "1148  https://www.coursera.org/learn/excel-basics-da...   \n",
       "\n",
       "                                     Course Description  \\\n",
       "2701  Process mining is the missing link between mod...   \n",
       "205   Science is undergoing a data explosion, and as...   \n",
       "2355  By now you have definitely heard about data sc...   \n",
       "1204  This course presents a gentle introduction int...   \n",
       "329   Data science is a team sport. As a data scienc...   \n",
       "2798  Digital health is rapidly being realised as th...   \n",
       "2710  Once you�ve identified a big data issue to ana...   \n",
       "2804  Apache Spark is the de-facto standard for larg...   \n",
       "1580  As data collection has increased exponentially...   \n",
       "1148  This course is designed to provide you with ba...   \n",
       "\n",
       "                                                 Skills  \n",
       "2701  process modeling  business process  Process Mi...  \n",
       "205   Computer Programming  Python Programming  SQL ...  \n",
       "2355  analysis  Machine Learning  software  Human Le...  \n",
       "1204  analytics  Data Analysis  physics  Exploratory...  \n",
       "329   Data Analysis  team management  Team Building ...  \n",
       "2798  data integrity  health human resources  Health...  \n",
       "2710  Databases  analytics  graphs  Data Structures ...  \n",
       "2804  General Statistics  Dimensionality Reduction  ...  \n",
       "1580  modeling  Databases  data retrieval  analysis ...  \n",
       "1148  euler's totient function  Pivot Table  workshe...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['data', 'science']\n",
    "\n",
    "# Count the number of occurrences of each keyword in each row\n",
    "counts = df['Course Description'].str.count('|'.join(keywords))\n",
    "\n",
    "# Sort the DataFrame in descending order by the number of occurrences\n",
    "sorted_df = df.iloc[(-counts).argsort()]\n",
    "\n",
    "# Select the top N rows\n",
    "top_rows = sorted_df.head(10)\n",
    "\n",
    "# Print the top N rows\n",
    "top_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "want VERB\n",
      "learn VERB\n",
      "data NOUN\n",
      "science NOUN\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(\"I wanting to learn data science\")\n",
    "keyword_pos_tags = ['NOUN', 'PROPN', 'VERB']\n",
    "for token in doc:\n",
    "    if token.pos_ in keyword_pos_tags:\n",
    "        print(token.lemma_, token.pos_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
